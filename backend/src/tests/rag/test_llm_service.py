import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from ml.rag_bot import LLMService, ChatMessage

print("ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º LLM Service...")

# –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
providers = [
    ("openai", "gpt-3.5-turbo"),
    ("anthropic", "claude-3-haiku-20240307"),
    ("local", "microsoft/DialoGPT-medium")
]

for provider, model in providers:
    print(f"\nüìã –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {provider}")
    
    try:
        llm = LLMService(provider=provider, model=model)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç—É—Å
        status = llm.get_status()
        print(f"‚úÖ –°—Ç–∞—Ç—É—Å: {status}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —á–∞—Ç
        print("üí¨ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ—Å—Ç–æ–π —á–∞—Ç...")
        messages = [
            ChatMessage(role="system", content="–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."),
            ChatMessage(role="user", content="–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?")
        ]
        
        response = llm.generate_chat_response(messages)
        print(f"ü§ñ –û—Ç–≤–µ—Ç: {response[:100]}...")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º RAG
        print("üìö –¢–µ—Å—Ç–∏—Ä—É–µ–º RAG...")
        question = "–ß—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?"
        context = """–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ ‚Äî —ç—Ç–æ –æ–±–ª–∞—Å—Ç—å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞, 
        –∫–æ—Ç–æ—Ä–∞—è –∏–∑—É—á–∞–µ—Ç –∞–ª–≥–æ—Ä–∏—Ç–º—ã –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã 
        –∏—Å–ø–æ–ª—å–∑—É—é—Ç –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —è–≤–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π."""
        sources = [{"filename": "ml_guide.txt", "similarity": 0.9}]
        
        rag_response = llm.generate_rag_response(question, context, sources)
        print(f"üìñ RAG –æ—Ç–≤–µ—Ç: {rag_response[:100]}...")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º {provider}: {e}")

print("\nüéâ –¢–µ—Å—Ç LLM Service –∑–∞–≤–µ—Ä—à–µ–Ω!")
print("\nüìù –ó–∞–º–µ—Ç–∫–∏:")
print("- –î–ª—è OpenAI —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
print("- –î–ª—è Anthropic —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install anthropic") 
print("- –î–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install transformers torch")
print("- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY –∏–ª–∏ ANTHROPIC_API_KEY")
print("- –ë–µ–∑ API –∫–ª—é—á–µ–π —Å–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ –∑–∞–≥–ª—É—à–∫–∏")